{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport scipy.stats as stats\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/data-storm-10/credit_card_default_train.csv\n/kaggle/input/data-storm-10/DATA STORM 1.0 - First Round Competition Guidlines.pdf\n/kaggle/input/data-storm-10/credit_card_default_test.csv\n/kaggle/input/data-storm-10/Credit_card_default - Business Problem - Assessment Criteria - Data Dictionary.xlsx\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/data-storm-10/credit_card_default_train.csv')\ntest_data = pd.read_csv('../input/data-storm-10/credit_card_default_test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data.dtypes.sample","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<bound method NDFrame.sample of Client_ID             object\nBalance_Limit_V1      object\nGender                object\nEDUCATION_STATUS      object\nMARITAL_STATUS        object\nAGE                   object\nPAY_JULY               int64\nPAY_AUG                int64\nPAY_SEP                int64\nPAY_OCT                int64\nPAY_NOV                int64\nPAY_DEC                int64\nDUE_AMT_JULY           int64\nDUE_AMT_AUG            int64\nDUE_AMT_SEP            int64\nDUE_AMT_OCT            int64\nDUE_AMT_NOV            int64\nDUE_AMT_DEC            int64\nPAID_AMT_JULY          int64\nPAID_AMT_AUG           int64\nPAID_AMT_SEP           int64\nPAID_AMT_OCT           int64\nPAID_AMT_NOV           int64\nPAID_AMT_DEC           int64\nNEXT_MONTH_DEFAULT     int64\ndtype: object>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def New_balance(x):\n    if x[-1]=='M':\n        x=float(x[:-1])*1000000\n    elif x[-1]=='K':\n        x=float(x[:-1])*1000\n    else:\n        x=float(x)\n    return(x)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"Balance_Limit_V1_new\"] = train_data[\"Balance_Limit_V1\"].apply(New_balance)\ntrain_data.drop(\"Balance_Limit_V1\",axis=1,inplace=True)\ntrain_data.rename(columns={\"Balance_Limit_V1_new\":\"Balance_Limit_V1\"},inplace=True)\ntrain_col = list(train_data.columns)\nlast = train_col.pop()\ntrain_col.insert(1,last)\ntrain_data= train_data[train_col]\n\ntest_data[\"Balance_Limit_V1_new\"] = test_data[\"Balance_Limit_V1\"].apply(New_balance)\ntest_data.drop(\"Balance_Limit_V1\",axis=1,inplace=True)\ntest_data.rename(columns={\"Balance_Limit_V1_new\":\"Balance_Limit_V1\"},inplace=True)\ntest_col = list(test_data.columns)\nlast = test_col.pop()\ntest_col.insert(1,last)\ntest_data= test_data[test_col]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender={\"M\":0 ,\"F\":1} \nstatus ={\"Single\":0 , \"Other\":1} \nstudy= {\"Graduate\":0 , \"High School\":1 , \"Other\":2} \nage= {\"Less than 30\":0 , \"31-45\":1, \"46-65\":2 , \"More than 65\":3}\n\ntrain_data.Gender = [gender[item] for item in train_data.Gender]\ntrain_data.EDUCATION_STATUS = [study[item] for item in train_data.EDUCATION_STATUS]\ntrain_data.MARITAL_STATUS = [status[item] for item in train_data.MARITAL_STATUS]\ntrain_data.AGE=[age[item] for item in train_data.AGE]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.Gender = [gender[item] for item in test_data.Gender]\ntest_data.EDUCATION_STATUS = [study[item] for item in test_data.EDUCATION_STATUS]\ntest_data.MARITAL_STATUS = [status[item] for item in test_data.MARITAL_STATUS]\ntest_data.AGE=[age[item] for item in test_data.AGE]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = train_data.pop(\"Client_ID\")\ny = train_data.pop(\"NEXT_MONTH_DEFAULT\")\n\nindex_test = test_data.pop(\"Client_ID\")","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( train_data, y, test_size=0.3)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\ntest_data = test_data.values","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscX = StandardScaler()\nX_train1 = scX.fit_transform(np.concatenate((X_train[:,0:1],X_train[:,12:]),axis=1))\nX_test1 = scX.transform(np.concatenate((X_test[:,0:1],X_test[:,12:]),axis=1))\ntest_data1 = scX.transform(np.concatenate((test_data[:,0:1],test_data[:,12:]),axis=1))\nnp.shape(X_train1)","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"(16800, 12)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = np.concatenate((X_train1,X_train[:,1:12]),axis=1)\nX_test1 = np.concatenate((X_test1,X_test[:,1:12]),axis=1)\ntest_data1 = np.concatenate((test_data1,test_data[:,1:12]),axis=1)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error,classification_report\n","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\nxgb_model.fit(X_train1, y_train)\n\ny_pred = xgb_model.predict(X_test1)\n\nprint(confusion_matrix(y_test, y_pred))","execution_count":15,"outputs":[{"output_type":"stream","text":"[[5323  260]\n [1033  584]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_pred,digits=4))","execution_count":19,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0     0.8375    0.9534    0.8917      5583\n           1     0.6919    0.3612    0.4746      1617\n\n    accuracy                         0.8204      7200\n   macro avg     0.7647    0.6573    0.6832      7200\nweighted avg     0.8048    0.8204    0.7980      7200\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = xgb_model.predict(test_data1)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op = {'Client_ID':index_test,'NEXT_MONTH_DEFAULT':prediction}\ndf = pd.DataFrame(op,columns=['Client_ID','NEXT_MONTH_DEFAULT'])\nexport_csv=df.to_csv('prediction.csv',index=None,header=True)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}