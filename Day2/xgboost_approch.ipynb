{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/data-storm-10/credit_card_default_train.csv')\n",
    "test_data = pd.read_csv('../input/data-storm-10/credit_card_default_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_balance(x):\n",
    "    if x[-1]=='M':\n",
    "        x=float(x[:-1])*1000000\n",
    "    elif x[-1]=='K':\n",
    "        x=float(x[:-1])*1000\n",
    "    else:\n",
    "        x=float(x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Balance_Limit_V1_new\"] = train_data[\"Balance_Limit_V1\"].apply(New_balance)\n",
    "train_data.drop(\"Balance_Limit_V1\",axis=1,inplace=True)\n",
    "train_data.rename(columns={\"Balance_Limit_V1_new\":\"Balance_Limit_V1\"},inplace=True)\n",
    "train_col = list(train_data.columns)\n",
    "last = train_col.pop()\n",
    "train_col.insert(1,last)\n",
    "train_data= train_data[train_col]\n",
    "\n",
    "test_data[\"Balance_Limit_V1_new\"] = test_data[\"Balance_Limit_V1\"].apply(New_balance)\n",
    "test_data.drop(\"Balance_Limit_V1\",axis=1,inplace=True)\n",
    "test_data.rename(columns={\"Balance_Limit_V1_new\":\"Balance_Limit_V1\"},inplace=True)\n",
    "test_col = list(test_data.columns)\n",
    "last = test_col.pop()\n",
    "test_col.insert(1,last)\n",
    "test_data= test_data[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train_data.pop(\"Client_ID\")\n",
    "y = train_data.pop(\"NEXT_MONTH_DEFAULT\")\n",
    "\n",
    "index_test = test_data.pop(\"Client_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"MARITAL_STATUS\"].replace({\"Other\": \"Other1\"}, inplace=True)\n",
    "test_data[\"MARITAL_STATUS\"].replace({\"Other\": \"Other1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes=[\"Gender\",\"AGE\",\"EDUCATION_STATUS\",\"MARITAL_STATUS\"]\n",
    "dummies=pd.concat([pd.get_dummies(train_data[col]) for col in changes], axis=1)\n",
    "train_data=pd.concat([train_data,dummies],axis=1)\n",
    "\n",
    "[train_data.pop(col) for col in changes]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_test=pd.concat([pd.get_dummies(test_data[col]) for col in changes], axis=1)\n",
    "test_data=pd.concat([test_data,dummies_test],axis=1)\n",
    "\n",
    "[test_data.pop(col) for col in changes]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( train_data, y, test_size=0.33 , random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "test_data = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "X_train1 = scX.fit_transform(np.concatenate((X_train[:,0:1],X_train[:,7:19]),axis=1))\n",
    "X_test1 = scX.transform(np.concatenate((X_test[:,0:1],X_test[:,7:19]),axis=1))\n",
    "test_data1 = scX.transform(np.concatenate((test_data[:,0:1],test_data[:,7:19]),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = np.concatenate((X_train1[:,0:1],np.around(X_train1[:,1:],decimals=2, out=None),X_train[:,1:7],X_train[:,19:]),axis=1)\n",
    "X_test1 = np.concatenate((X_test1[:,0:1],np.around(X_test1[:,1:],decimals=2, out=None),X_test[:,1:7],X_test[:,19:]),axis=1)\n",
    "test_data1 = np.concatenate((test_data1[:,0:1],np.around(test_data1[:,1:],decimals=2, out=None),test_data[:,1:7],test_data[:,19:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train1, y_train)\n",
    "\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "thresholds = [0.0109]\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train1)\n",
    "    # train model\n",
    "    selection_model = XGBClassifier(learning_rate =0.001,n_estimators=1000, max_depth=6, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "                                    colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1,\n",
    "                                    seed=30, random_state=7)\n",
    "\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test1)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Thresh=%.4f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_test = selection.transform(test_data1)\n",
    "prediction = selection_model.predict(select_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#op = {'Client_ID':index_test,'NEXT_MONTH_DEFAULT':prediction}\n",
    "#df = pd.DataFrame(op,columns=['Client_ID','NEXT_MONTH_DEFAULT'])\n",
    "#vexport_csv=df.to_csv('prediction_day2_4.csv',index=None,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
